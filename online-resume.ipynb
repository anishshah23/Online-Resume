{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anish Shah  \n",
    "==============\n",
    "---\n",
    "New York\n",
    "USA   (Ready for relocation)\n",
    "\n",
    "----\n",
    "## Portfolio\n",
    " - Email Address: anish23@ymail.com  Education: anishcha@buffalo.edu  \n",
    " - Number: (716)587-1789\n",
    " - Linkdin profile : [Linkedin](https://www.linkedin.com/in/anish23/)   \n",
    " - [Github Profile](https://github.com/anishshah23)\n",
    " - Data Scientist with experience in Data Mining, Data Analytics, Natural Language Processing and Big Data Programming with primary emphasis on Machine Learning and Artificial Intelligence. . \n",
    " \n",
    "------------------ \n",
    "## Projects ##\n",
    "------------------\n",
    "## 1.Text Classification using Spark:\n",
    "- Goal:Processing graph data using Spark Applying my data analytics knowledge (word frequency, word-co-occurrence) and machine learning skills to perform multi-class classification of text data using Apache Spark.  \n",
    "- Skills Learned: Data cleaning, Data pipeline, Model building, Machine Learning, Gridsearch, randomize search, Hyper parameter tuning.\n",
    "- Detail: Built a data pipeline using a. Data from sources such as NY Times articles using the APIs provided by the data sources. b. Split the data into training and test data set. c. Extracted features that will determine the class or category of the article {politics, sports, business, etc} d. Built a model for classification using classification algorithms such as Logistic regression, Naive Bayes ,and Random Forest. e. Compare the classification accuracy of at least two well-known classification algorithms, for a given text data set.  \n",
    "- [Code Details](https://github.com/anishshah23/Data-Analytics-pipeline-using-Spark)\n",
    "\n",
    "## 2.Data Aggregation and Big Data Analysis\n",
    "- Goal: Data aggregation from Twitter and NYTimes using the APIs exposed by data sources, applying classical big data analytic method of MapReduce to the unstructured data collected, and building a visualization data product.\n",
    "- Skills learned – Python, Pandas, Model building, Exploratory Analysis, Hadoop, D3.js \n",
    "- [Code Details](https://github.com/anishshah23/-DATA-AGGREGATION-BIG-DATA-ANALYSIS-AND-VISUALIZATION)\n",
    "\n",
    "\n",
    "## 3.Boston Housing Data Analysis:\n",
    "- Skills learned: R, Regression, Visualisations\n",
    "- Goal: Analyzed the areas with high crime rates and drawing conclusions for the increased crime rates in these areas. Performed data analysis to obtain the relationship between the predictors.\n",
    "- Data analysis by using R.\n",
    "- [Code Details](https://github.com/anishshah23/Boston-Housing-Data-Analysis-)\n",
    "\n",
    "## 4.Handwritten digits classification:\n",
    "- Skills learned: Python, NumPy, Scipy\n",
    "- Goal: Implemented multilayer perceptron neural networks in the classification of handwritten digits on MNIST dataset.\n",
    "- [Code Details](https://github.com/anishshah23/Handwritten-digits-classification)\n",
    "\n",
    "## 5.NYC-Uber-Data-Analysis:\n",
    "- Goal: : Using quantitative data analysis methods visualized Uber’s ridership growth, characterized the demand based on identified patterns in the time series, estimated the value of the NYC market for Uber and its revenue growth, analyzed the trip duration to determine the probability distribution model and also insights about the usage of the service.\n",
    "- Skills learned: Python, NumPy, Scipy, Pandas, SQL, Matplotlib.\n",
    "- [Code Details](https://github.com/anishshah23/NYC-Uber-Data-Analysis)\n",
    "\n",
    "## 6.Regression:\n",
    "- Skills Learned- Multiple Linear regression, Python, Pandas, Numpy, scikitlearn\n",
    "- Goal: Implementing Regression techniques such as Linear Discriminant Analysis (LDA), Quadratic Discriminant Analysis (QDA), Linear regression, Ridge regression, Ridge Regression using Gradient Descent and Non-linear regression to understand how machine learning functions work.\n",
    "- [Code Details](https://github.com/anishshah23/Regression)\n",
    "\n",
    "## 7.Classification and Regression:\n",
    "- Skills Learned: Logistic Regression, Python, Support Vector Machines, Scikit-learn, Multi- Class Logistic Regression.\n",
    "- Implemented Logistic Regression to give the prediction results. Used the Support Vector Machine (SVM) toolbox sklearn.svm.SVM to perform classification.\n",
    "- Implemented the gradient descent minimization of multi-class Logistic Regression (using softmax function).\n",
    "- [Code Details](https://github.com/anishshah23/Classification-and-Regression)\n",
    "\n",
    "## 8.PCA and K-Means Clustering Of High Dimensional Aircraft Data :\n",
    "- Goal: Executed PCA and K-Means Clustering on Delta airlines high dimensional dataset to obtain some interesting findings. \n",
    "- Kaggle Public Dashboard Accuracy: 75 Percent(Rank<1000)\n",
    "- [Code Details](https://github.com/anishshah23/PCA-and-K-Means-Clustering-Of-High-Dimensional-Aircraft-Data-)\n",
    "\n",
    "## 9.Web scraping(Twitter) :\n",
    "- Libraries: Beautiful Soup, Pandas, Numpy , Google Maps API \n",
    "- Goal: To scrape the data from the HTML pages into the Pandas data frame.\n",
    "- We were interested in sheer number of tweets on a topic that is associated with “flu” or a related term that you uniquely determine that will be important influencer. Using the Search API collected at least 20000 tweets. Grouped them by geo-location as in Google maps API and plotted them on the map of USA. Mapped the geolocations to states, and color the states according to the number of tweets or mentions per state.\n",
    "- [Code Details](https://github.com/anishshah23/Social-Network-analysis-on-Twitter-Data)\n",
    "\n",
    "## 10.IMDb 5000 Data analysis:\n",
    "- Skills: R, Decision Trees, Random Forest, Multiple Linear Regression\n",
    "-  Analyzed the IMDb 5000 Movie Dataset from Kaggle to predict movie ratings and gained some meaningful insights by using different methodologies such as Multiple Linear Regression, Decision Tree and Random Forest.\n",
    "\n",
    "-----------------\n",
    "## Skills\n",
    "-------------------\n",
    "## Coursework:\n",
    "\n",
    "- **Data-Intensive Computing, Machine Learning, Data Mining, Probability, Computational Algebra, Databases, Distributed Systems, Cloud Computing, Data Structures, Design and Analysis of Algorithms.\n",
    "**\n",
    "-------------------\n",
    "\n",
    "## Software Tools:\n",
    "- Libraries:  **Pandas, Numpy, Sklearn, scipy, TensorFlow (Deep learning), PySpark, Matplotlib, H2o, Keras, Dplyr, data.table, Lubridate, ggplot2, Plotly, Caret, XGBoost, Glmnet, Rshiny.**\n",
    "\n",
    "---------------------\n",
    "## Programming Languages: \n",
    "- **R Programming, Hadoop, (Hive, Pig, Spark), Python, SQL, MATLAB.\n",
    "**\n",
    "---------------\n",
    "\n",
    "## Tools:\n",
    "------------\n",
    "- **AWS, Microsoft Excel, Tableau, Ipython Notebook, Google Analytics, Google Data studio, ETL, Data Warehouse, KPI\n",
    "**\n",
    "---------------------\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
